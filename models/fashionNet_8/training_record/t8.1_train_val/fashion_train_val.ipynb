{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') # Must be before importing matplotlib.pyplot or pylab!\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0,'/local2/home/tong/caffe-master/python')\n",
    "import caffe\n",
    "\n",
    "import os\n",
    "from matplotlib import rc\n",
    "rc('mathtext', default='regular')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "caffe.set_mode_gpu()\n",
    "caffe.set_device(0)\n",
    "\n",
    "solver = caffe.SGDSolver('/local2/home/tong/fashionRecommendation/models/fashionNet_8/fashion_solver_8.prototxt')\n",
    "\n",
    "# Continue!!!\n",
    "solver.net.copy_from('/local2/home/tong/fashionRecommendation/models/VGG_M_2048/VGG_CNN_M_2048.caffemodel')\n",
    "# solver.net.copy_from('/local2/home/tong/fashionRecommendation/models/fashionNet_2/training_record/t2.1/fashion_params_2_124200.caffemodel')\n",
    "\n",
    "# Continue!!!\n",
    "solver.test_nets[0].copy_from('/local2/home/tong/fashionRecommendation/models/VGG_M_2048/VGG_CNN_M_2048.caffemodel')\n",
    "# solver.test_nets[0].copy_from('/local2/home/tong/fashionRecommendation/models/fashionNet_2/training_record/t2.1/fashion_params_2_124200.caffemodel')\n",
    "\n",
    "# for saving caffemodel\n",
    "net = caffe.Net('/local2/home/tong/fashionRecommendation/models/fashionNet_8/fashion_deploy_8.prototxt', caffe.TEST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_avg(test_iter,i_train,val_batch_size):\n",
    "    \n",
    "    avg_accu = 0\n",
    "    avg_loss = 0\n",
    "\n",
    "    val_data_fp_temp0 = str(i_train)\n",
    "    val_data_fp_temp1 = ''\n",
    "    \n",
    "    for i in range(0,test_iter):\n",
    "        \n",
    "        if (i%50==0 or (i==(test_iter-1))):\n",
    "            print(\"{}/{}\\n\".format(i+1,test_iter))\n",
    "            \n",
    "        solver.test_nets[0].forward()\n",
    "        \n",
    "        avg_accu = avg_accu + solver.test_nets[0].blobs['accuracy'].data\n",
    "        avg_loss = avg_loss + solver.test_nets[0].blobs['rank_Loss'].data\n",
    "\n",
    "        for t in range(0,val_batch_size):\n",
    "            val_data_fp_temp0 += ' '+solver.test_nets[0].blobs['like'].data[t]\n",
    "            val_data_fp_temp1 += ' '+solver.test_nets[0].blobs['like_n'].data[t]\n",
    "        \n",
    "        val_data_fp_temp0 += val_data_fp_temp1\n",
    "        \n",
    "    return (avg_accu/test_iter), (avg_loss/test_iter), val_data_fp_temp0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recordDir = '/local2/home/tong/fashionRecommendation/models/fashionNet_8/training_record/t8.1_train_val/'\n",
    "\n",
    "test_interval = 3232 # 1/10 training epoch\n",
    "test_iter = 400 # 1/10 validation epoch\n",
    "visual_interval = 4 # every 4 iters\n",
    "train_iters = 32320 # 1 training epoch\n",
    "\n",
    "k = 0\n",
    "start_iter = 0 # Continue!!!\n",
    "end_iter = start_iter+train_iters*8 # t8.1(next i=0)[8_0.0001*(1,100)] Continue!!!\n",
    "\n",
    "params = net.params.keys()\n",
    "\n",
    "solver.net.forward()\n",
    "\n",
    "train_batch_size = len(solver.net.blobs['top'].data)\n",
    "val_batch_size = len(solver.test_nets[0].blobs['top'].data)\n",
    "\n",
    "train_accu = (start_iter+1)*0 # Continue!!!\n",
    "train_los = (start_iter+1)*0 # Continue!!!\n",
    "\n",
    "train_avg_accu = 0\n",
    "train_avg_loss = 0\n",
    "\n",
    "train_cur_accu = 0\n",
    "train_cur_loss = 0\n",
    "\n",
    "test_accu = 0\n",
    "test_loss = 0\n",
    "\n",
    "for i in range (start_iter,end_iter+1):\n",
    "#     if (i != start_iter): # Continue!!!\n",
    "    # train_avg_accu/loss.txt\n",
    "    train_accu = train_accu + solver.net.blobs['accuracy'].data\n",
    "    train_los = train_los + solver.net.blobs['rank_loss'].data\n",
    "    train_avg_accu = train_accu/(i+1)\n",
    "    train_avg_loss = train_los/(i+1)\n",
    "    train_avg_accu_fp = open(recordDir+'train_avg_accu.txt','a')\n",
    "    train_avg_loss_fp = open(recordDir+'train_avg_loss.txt','a')\n",
    "    train_avg_accu_fp.write(str(i)+' '+str(train_avg_accu)+'\\r\\n')\n",
    "    train_avg_loss_fp.write(str(i)+' '+str(train_avg_loss)+'\\r\\n')\n",
    "    train_avg_accu_fp.close()\n",
    "    train_avg_loss_fp.close()\n",
    "    if(i%visual_interval==0):\n",
    "        print(\"\\nIters done:{}, train_avg_accu={}, train_avg_loss={}.\\n\".format(i,train_avg_accu,train_avg_loss))\n",
    "    # train_bat_accu/loss.txt\n",
    "    train_cur_accu = solver.net.blobs['accuracy'].data\n",
    "    train_cur_loss = solver.net.blobs['rank_loss'].data \n",
    "    train_bat_accu_fp = open(recordDir+'train_bat_accu.txt','a')\n",
    "    train_bat_loss_fp = open(recordDir+'train_bat_loss.txt','a')\n",
    "    train_bat_accu_fp.write(str(i)+' '+str(train_cur_accu)+'\\r\\n')\n",
    "    train_bat_loss_fp.write(str(i)+' '+str(train_cur_loss)+'\\r\\n')\n",
    "    train_bat_accu_fp.close()\n",
    "    train_bat_loss_fp.close()\n",
    "    if(i%visual_interval==0):\n",
    "        print(\"                 train_bat_accu={}, train_bat_loss={}.\\n\".format(train_cur_accu,train_cur_loss))\n",
    "    # train_data.txt\n",
    "    train_data_fp = open(recordDir+'train_data.txt','a')\n",
    "    train_data_fp_temp0 = str(i)\n",
    "    train_data_fp_temp1 = ''\n",
    "    for t in range(0,train_batch_size):\n",
    "        train_data_fp_temp0 += ' '+solver.net.blobs['like'].data[t]\n",
    "        train_data_fp_temp1 += ' '+solver.net.blobs['like_n'].data[t]\n",
    "    train_data_fp_temp0 += train_data_fp_temp1\n",
    "    train_data_fp.write(train_data_fp_temp0+'\\r\\n')\n",
    "    train_data_fp.close()   \n",
    "    # validation, save caffemodel, visualization, and stop criteria\n",
    "    if (i%test_interval==0 or i==end_iter):\n",
    "        # val_bat_accu/loss.txt\n",
    "        test_accu,test_loss,\\\n",
    "        val_data_fp_temp0\n",
    "        = \\\n",
    "        test_avg(test_iter,i,val_batch_size)\n",
    "        val_bat_accu_fp = open(recordDir+'val_bat_accu.txt','a')\n",
    "        val_bat_loss_fp = open(recordDir+'val_bat_loss.txt','a')\n",
    "        val_bat_accu_fp.write(str(i)+str(test_accu)+'\\r\\n')\n",
    "        val_bat_loss_fp.write(str(i)+str(test_loss)+'\\r\\n')\n",
    "        val_bat_accu_fp.close()\n",
    "        val_bat_loss_fp.close()\n",
    "        # val_data.txt\n",
    "        val_data_fp = open(recordDir+'val_data.txt','a')\n",
    "        val_data_fp.write(val_data_fp_temp0+'\\r\\n')\n",
    "        val_data_fp.close()\n",
    "        # save caffemodel\n",
    "        source_params = {pr: (solver.net.params[pr][0].data,solver.net.params[pr][1].data) for pr in params}\n",
    "        target_params = {pr: (net.params[pr][0].data,net.params[pr][1].data) for pr in params}\n",
    "        for pr in params:\n",
    "            target_params[pr][0][...] = source_params[pr][0] #weights\n",
    "            target_params[pr][1][...] = source_params[pr][1] #bias\n",
    "        net.save(recordDir+'fashion_params_8_'+str(i)+'.caffemodel') \n",
    "        # avg_bat_record.png\n",
    "        train_accu_whole = []\n",
    "        train_loss_whole = []\n",
    "        test_accu_whole = []\n",
    "        test_loss_whole = []\n",
    "        train_accu_whole = open(recordDir+'train_avg_accu.txt').readlines() \n",
    "        train_loss_whole = open(recordDir+'train_avg_loss.txt').readlines()\n",
    "        test_accu_whole = open(recordDir+'val_bat_accu.txt').readlines()\n",
    "        test_loss_whole = open(recordDir+'val_bat_loss.txt').readlines()\n",
    "        train_iter_idx = []\n",
    "        train_loss = []\n",
    "        train_accuracy = []\n",
    "        test_iter_idx = []\n",
    "        test_loss = []\n",
    "        test_accuracy = []\n",
    "        for i in range(0, len(train_accu_whole)):\n",
    "            if i % 300 == 0: # 1/100 training epoch\n",
    "                train_iter_idx.append(int(train_accu_whole[i].strip('\\r\\n').split(' ')[0]))\n",
    "                train_loss.append(float(train_loss_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "                train_accuracy.append(float(train_accu_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "        for i in range(0, len(test_accu_whole)):\n",
    "            test_iter_idx.append(int(test_accu_whole[i].strip('\\r\\n').split(' ')[0]))\n",
    "            test_loss.append(float(test_loss_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "            test_accuracy.append(float(test_accu_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "        fig = plt.figure()\n",
    "        ax_left = fig.add_subplot(111)\n",
    "        ax_left.plot(train_iter_idx, train_loss, '--rp', label = 'Avg_T_Loss')\n",
    "        ax_left.plot(test_iter_idx, test_loss, '--gp', label = 'Avg_V_Loss')\n",
    "        ax_right = ax_left.twinx()\n",
    "        ax_right.plot(train_iter_idx, train_accuracy, '-bp', label = 'Avg_T_Accuracy')\n",
    "        ax_right.plot(test_iter_idx, test_accuracy, '-yp', label = 'Avg_V_Accuracy')\n",
    "        lines_left, labels_left = ax_left.get_legend_handles_labels()\n",
    "        lines_right, labels_right = ax_right.get_legend_handles_labels()\n",
    "        ax_right.legend(lines_left + lines_right, labels_left + labels_right, loc=0)\n",
    "        ax_left.grid()\n",
    "        ax_left.set_xlabel(\"Training Iterations Done(n)\")\n",
    "        ax_left.set_ylabel(\"Loss\")\n",
    "        ax_right.set_ylabel(\"Accuracy\")\n",
    "        ax_right.set_title(\"HVA@({:.3f},{}), LVL@({:.3f},{})\".format(max(test_accuracy),test_iter_idx[test_accuracy.index(max(test_accuracy))],min(test_loss),test_iter_idx[test_loss.index(min(test_loss))]))\n",
    "        plt.savefig(recordDir+'avg_bat_record.png', bbox_inches='tight')\n",
    "        plt.close('all')\n",
    "        # bat_bat_record.png\n",
    "        train_accu_whole = []\n",
    "        train_loss_whole = []\n",
    "        train_accu_whole = open(recordDir+'train_bat_accu.txt').readlines() \n",
    "        train_loss_whole = open(recordDir+'train_bat_loss.txt').readlines()\n",
    "        train_iter_idx = []\n",
    "        train_loss = []\n",
    "        train_accuracy = []\n",
    "        for i in range(0, len(train_accu_whole)):\n",
    "            if i % 300 == 0: # 1/100 training epoch\n",
    "                train_iter_idx.append(int(train_accu_whole[i].strip('\\r\\n').split(' ')[0]))\n",
    "                train_loss.append(float(train_loss_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "                train_accuracy.append(float(train_accu_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "        fig = plt.figure()\n",
    "        ax_left = fig.add_subplot(111)\n",
    "        ax_left.plot(train_iter_idx, train_loss, '--rp', label = 'Bat_T_Loss')\n",
    "        ax_left.plot(test_iter_idx, test_loss, '--gp', label = 'Avg_V_Loss')\n",
    "        ax_right = ax_left.twinx()\n",
    "        ax_right.plot(train_iter_idx, train_accuracy, '-bp', label = 'Bat_T_Accuracy')\n",
    "        ax_right.plot(test_iter_idx, test_accuracy, '-yp', label = 'Avg_V_Accuracy')\n",
    "        lines_left, labels_left = ax_left.get_legend_handles_labels()\n",
    "        lines_right, labels_right = ax_right.get_legend_handles_labels()\n",
    "        ax_right.legend(lines_left + lines_right, labels_left + labels_right, loc=0)\n",
    "        ax_left.grid()\n",
    "        ax_left.set_xlabel(\"Training Iterations Done(n)\")\n",
    "        ax_left.set_ylabel(\"Loss\")\n",
    "        ax_right.set_ylabel(\"Accuracy\")\n",
    "        ax_right.set_title(\"HVA@({:.3f},{}), LVL@({:.3f},{})\".format(max(test_accuracy),test_iter_idx[test_accuracy.index(max(test_accuracy))],min(test_loss),test_iter_idx[test_loss.index(min(test_loss))]))\n",
    "        plt.savefig(recordDir+'bat_bat_record.png', bbox_inches='tight')\n",
    "        plt.close('all')\n",
    "        # stop criteria\n",
    "        if test_accu > 0.93:\n",
    "            k = k + 1\n",
    "            if (k > 10):\n",
    "                print '\\n\\nValidation accuracy: {} > 0.93 counted for 10 times\\n\\n'.format(test_accu)\n",
    "                break\n",
    "    # update parameters\n",
    "    solver.step(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
