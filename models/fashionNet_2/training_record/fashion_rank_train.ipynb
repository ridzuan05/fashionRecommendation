{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') # Must be before importing matplotlib.pyplot or pylab!\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0,'/local2/home/tong/caffe-master/python')\n",
    "import caffe\n",
    "\n",
    "import os\n",
    "from matplotlib import rc\n",
    "rc('mathtext', default='regular')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "caffe.set_mode_gpu()\n",
    "caffe.set_device(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for training\n",
    "solver = caffe.SGDSolver('/local2/home/tong/fashionRecommendation/models/fashionNet_3/fashion_solver_3.prototxt')\n",
    "#CHANGE!!!\n",
    "# solver.net.copy_from('/local2/home/tong/fashionRecommendation/models/VGG_M_2048/VGG_CNN_M_2048.caffemodel')\n",
    "#CHANGE!!!\n",
    "# solver.test_nets[0].copy_from('/local2/home/tong/fashionRecommendation/models/VGG_M_2048/VGG_CNN_M_2048.caffemodel')\n",
    "# solver.net.copy_from('/local2/home/tong/fashionRecommendation/models/fashionNet_2/training_record/fashion_params_2_91448.caffemodel')\n",
    "# solver.test_nets[0].copy_from('/local2/home/tong/fashionRecommendation/models/fashionNet_2/training_record/fashion_params_2_91448.caffemodel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_avg(test_iter,iters):\n",
    "    avg_accu = 0\n",
    "    avg_loss = 0\n",
    "    y_l_true = []\n",
    "    y_l_pred = []\n",
    "    y_r_true = []\n",
    "    y_r_pred = []\n",
    "    dd_dislike = 0\n",
    "    dd_count = 0\n",
    "    dl_dislike = 0\n",
    "    dl_count = 0\n",
    "    ld_like = 0\n",
    "    ld_count = 0\n",
    "    ll_like = 0\n",
    "    ll_count = 0\n",
    "    for i in range(0,test_iter):\n",
    "        if (i%50==0 or (i==(test_iter-1))):\n",
    "            print(\"{}/{} @ {}\\n\".format(i+1,test_iter,iters))\n",
    "        solver.test_nets[0].forward()\n",
    "        avg_accu = avg_accu + solver.test_nets[0].blobs['accuracy'].data\n",
    "        avg_loss = avg_loss + solver.test_nets[0].blobs['rank_Loss'].data\n",
    "        for j in range(0,len(solver.test_nets[0].blobs['label_top'].data)):\n",
    "            y_l_pred.append(0 if solver.test_nets[0].blobs['metric_fc3'].data[j][0]>solver.test_nets[0].blobs['metric_fc3'].data[j][1] else 1)\n",
    "            y_l_true.append(1)\n",
    "            y_r_pred.append(0 if solver.test_nets[0].blobs['metric_fc3_n'].data[j][0]>solver.test_nets[0].blobs['metric_fc3_n'].data[j][1] else 1)\n",
    "            y_r_true.append(0)\n",
    "            #dd\n",
    "            if (solver.test_nets[0].blobs['metric_fc3_n'].data[j][0]>solver.test_nets[0].blobs['metric_fc3_n'].data[j][1]):\n",
    "                dd_count = dd_count + 1\n",
    "                dd_dislike = dd_dislike + solver.test_nets[0].blobs['metric_fc3_softmax_n'].data[j][0]\n",
    "            #dl\n",
    "            else:\n",
    "                dl_count = dl_count + 1\n",
    "                dl_dislike = dl_dislike + solver.test_nets[0].blobs['metric_fc3_softmax_n'].data[j][0]\n",
    "            #ld\n",
    "            if (solver.test_nets[0].blobs['metric_fc3'].data[j][0]>solver.test_nets[0].blobs['metric_fc3'].data[j][1]):\n",
    "                ld_count = ld_count + 1\n",
    "                ld_like = ld_like + solver.test_nets[0].blobs['metric_fc3_softmax'].data[j][1]\n",
    "            #ll\n",
    "            else:\n",
    "                ll_count = ll_count + 1\n",
    "                ll_like = ll_like + solver.test_nets[0].blobs['metric_fc3_softmax'].data[j][1]\n",
    "    cMat_l = confusion_matrix(y_l_true, y_l_pred)\n",
    "    if(len(cMat_l)==1):\n",
    "        cMat_l = [[0,0],[0,cMat_l[0][0]]]\n",
    "    cMat_r = confusion_matrix(y_r_true, y_r_pred)\n",
    "    if(len(cMat_r)==1):\n",
    "        cMat_r = [[cMat_r[0][0],0],[0,0]]\n",
    "    return (avg_accu/test_iter), (avg_loss/test_iter),cMat_l,cMat_r, \\\n",
    "           (dd_dislike/dd_count), (dl_dislike/dl_count), ((dd_dislike+dl_dislike)/(dd_count+dl_count)), \\\n",
    "           (ld_like/ld_count), (ll_like/ll_count), ((ld_like+ll_like)/(ld_count+ll_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_iter = 450\n",
    "# test_accu,test_loss,cMat_l,cMat_r=test_avg(test_iter)\n",
    "# print(\"test_accu: {}\\n\".format(test_accu))\n",
    "# print(\"test_loss: {}\\n\".format(test_loss))\n",
    "# print(\"cMat_l:\\n\")\n",
    "# print(cMat_l)\n",
    "# print(\"\\ncMat_r:\\n\")\n",
    "# print(cMat_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recordDir = '/local2/home/tong/fashionRecommendation/models/fashionNet_2/training_record/'\n",
    "test_interval = 184 # 1/50 train epoch\n",
    "test_iter = 450 # 1 test epoch\n",
    "start_iter = 49128\n",
    "end_iter = 9178*(7+3) #7+3 epoch\n",
    "for i in range(start_iter,end_iter+1):\n",
    "    if (i%test_interval==0 or i==end_iter):\n",
    "        #validation & conf_matrix\n",
    "        solver.test_nets[0].copy_from(recordDir+'fashion_params_2_'+str(i)+'.caffemodel')\n",
    "        test_accu,test_loss,cMat_l,cMat_r,dd_dislike,dl_dislike,d_dislike,ld_like,ll_like,l_like=test_avg(test_iter,i)\n",
    "        test_rank_accu = open(recordDir + 'test_rank_accu.txt','a')\n",
    "        test_rank_loss = open(recordDir + 'test_rank_loss.txt','a')\n",
    "        test_rank_accu.write(str(i)+' '+str(test_accu)+'\\r\\n')\n",
    "        test_rank_loss.write(str(i)+' '+str(test_loss)+'\\r\\n')\n",
    "        test_rank_accu.close()\n",
    "        test_rank_loss.close()\n",
    "        te_l_conf = open(recordDir + 'conf_l_matrix.txt','a')\n",
    "        te_l_conf.write(str(i)+' '+str(cMat_l[0][0])+' '+str(cMat_l[0][1])+' '+str(cMat_l[1][0])+' '+str(cMat_l[1][1])+'\\r\\n')\n",
    "        te_l_conf.close()\n",
    "        te_r_conf = open(recordDir + 'conf_r_matrix.txt','a')\n",
    "        te_r_conf.write(str(i)+' '+str(cMat_r[0][0])+' '+str(cMat_r[0][1])+' '+str(cMat_r[1][0])+' '+str(cMat_r[1][1])+'\\r\\n')\n",
    "        te_r_conf.close()\n",
    "        dd_f = open(recordDir + 'dd_dislike.txt','a')\n",
    "        dd_f.write(str(i)+' '+str(dd_dislike)+'\\r\\n')\n",
    "        dd_f.close()\n",
    "        dl_f = open(recordDir + 'dl_dislike.txt','a')\n",
    "        dl_f.write(str(i)+' '+str(dl_dislike)+'\\r\\n')\n",
    "        dl_f.close()\n",
    "        d_f = open(recordDir + 'd_dislike.txt','a')\n",
    "        d_f.write(str(i)+' '+str(d_dislike)+'\\r\\n')\n",
    "        d_f.close()\n",
    "        ld_f = open(recordDir + 'ld_like.txt','a')\n",
    "        ld_f.write(str(i)+' '+str(ld_like)+'\\r\\n')\n",
    "        ld_f.close()\n",
    "        ll_f = open(recordDir + 'll_like.txt','a')\n",
    "        ll_f.write(str(i)+' '+str(ll_like)+'\\r\\n')\n",
    "        ll_f.close()\n",
    "        l_f = open(recordDir + 'l_like.txt','a')\n",
    "        l_f.write(str(i)+' '+str(l_like)+'\\r\\n')\n",
    "        l_f.close()\n",
    "        print(\"\\nIters done:{}, VAL_accu={}, VAL_loss={}.\\n\".format(i,test_accu,test_loss))\n",
    "        #visualization\n",
    "        test_accu_whole = []\n",
    "        test_loss_whole = []\n",
    "        test_accu_whole = open(recordDir+'test_rank_accu.txt').readlines()\n",
    "        test_loss_whole = open(recordDir+'test_rank_loss.txt').readlines()\n",
    "        test_iter_idx = []\n",
    "        test_loss = []\n",
    "        test_accuracy = []\n",
    "        for i in range(0, len(test_accu_whole)):\n",
    "            #test_iter_idx\n",
    "            test_iter_idx.append(int(test_accu_whole[i].strip('\\r\\n').split(' ')[0]))\n",
    "            #test_loss\n",
    "            test_loss.append(float(test_loss_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "            #test_accuracy\n",
    "            test_accuracy.append(float(test_accu_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "        fig = plt.figure()\n",
    "        ax_left = fig.add_subplot(111)\n",
    "        ax_left.plot(test_iter_idx, test_loss, '--gp', label = 'Avg_V_Loss')\n",
    "        ax_right = ax_left.twinx()\n",
    "        ax_right.plot(test_iter_idx, test_accuracy, '-yp', label = 'Avg_V_Accuracy')\n",
    "        # ask matplotlib for the plotted objects and their labels\n",
    "        lines_left, labels_left = ax_left.get_legend_handles_labels()\n",
    "        lines_right, labels_right = ax_right.get_legend_handles_labels()\n",
    "        ax_right.legend(lines_left + lines_right, labels_left + labels_right, loc=0)\n",
    "        ax_left.grid()\n",
    "        ax_left.set_xlabel(\"Training Iterations Done(n)\")\n",
    "        ax_left.set_ylabel(\"Loss\")\n",
    "        ax_right.set_ylabel(\"Accuracy\")\n",
    "        ax_right.set_title(\"HVA@({:.3f},{}), LVL@({:.3f},{})\".format(max(test_accuracy),test_iter_idx[test_accuracy.index(max(test_accuracy))],min(test_loss),test_iter_idx[test_loss.index(min(test_loss))]))\n",
    "        plt.savefig(recordDir+'rank_record.png', bbox_inches='tight')   \n",
    "        conf_l_matrix_whole = []\n",
    "        conf_r_matrix_whole = []\n",
    "        conf_l_matrix_whole = open(recordDir+'conf_l_matrix.txt').readlines()\n",
    "        conf_r_matrix_whole = open(recordDir+'conf_r_matrix.txt').readlines()\n",
    "        conf_matrix = []\n",
    "        for i in range(0,len(conf_l_matrix_whole)):\n",
    "            conf_matrix.append([int(conf_r_matrix_whole[i].split(' ')[1]),int(conf_r_matrix_whole[i].split(' ')[2]), \\\n",
    "                                int(conf_l_matrix_whole[i].split(' ')[3]),int(conf_l_matrix_whole[i].split(' ')[4])])\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        im = ax.imshow(np.array(conf_matrix).T, interpolation='nearest', cmap=plt.cm.jet)\n",
    "        fig.colorbar(im, ax=ax)\n",
    "        plt.xlabel('Caffemodel Index(n)')\n",
    "        plt.ylabel('like(like,dislike), dislike(like,dislike)')\n",
    "        plt.title('Confusion Matrix@(dislike,like)')\n",
    "        ax.set_aspect(25)\n",
    "        fig.set_size_inches(20.5, 12.5)\n",
    "        fig.savefig(recordDir+'cMat.png',bbox_inches='tight')\n",
    "        dd_dislike_whole = []\n",
    "        dl_dislike_whole = []\n",
    "        d_dislike_whole = []\n",
    "        ld_like_whole = []\n",
    "        ll_like_whole = []\n",
    "        l_like_whole = []\n",
    "        dd_dislike_whole = open(recordDir+'dd_dislike.txt').readlines()\n",
    "        dl_dislike_whole = open(recordDir+'dl_dislike.txt').readlines()\n",
    "        d_dislike_whole = open(recordDir+'d_dislike.txt').readlines()\n",
    "        ld_like_whole = open(recordDir+'ld_like.txt').readlines()\n",
    "        ll_like_whole = open(recordDir+'ll_like.txt').readlines()\n",
    "        l_like_whole = open(recordDir+'l_like.txt').readlines()        \n",
    "        iters_idx = []\n",
    "        dd_dislike = []\n",
    "        dd_like = []\n",
    "        dl_dislike = []\n",
    "        dl_like = []\n",
    "        d_dislike = []\n",
    "        d_like = []\n",
    "        ld_like = []\n",
    "        ld_dislike = []\n",
    "        ll_like = []\n",
    "        ll_dislike = []\n",
    "        l_like = []\n",
    "        l_dislike = []\n",
    "        for i in range(0, len(dd_dislike_whole)):\n",
    "            iters_idx.append(int(dd_dislike_whole[i].strip('\\r\\n').split(' ')[0]))\n",
    "            dd_dislike.append(float(dd_dislike_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "            dd_like.append(1-dd_dislike[i])\n",
    "            dl_dislike.append(float(dl_dislike_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "            dl_like.append(1-dl_dislike[i])\n",
    "            d_dislike.append(float(d_dislike_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "            d_like.append(1-d_dislike[i])\n",
    "            ld_like.append(float(ld_like_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "            ld_dislike.append(1-ld_like[i])\n",
    "            ll_like.append(float(ll_like_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "            ll_dislike.append(1-ll_like[i])\n",
    "            l_like.append(float(l_like_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "            l_dislike.append(1-l_like[i])\n",
    "        #dd\n",
    "        fig = plt.figure()\n",
    "        ax_left = fig.add_subplot(111)\n",
    "        ax_left.plot(iters_idx, dd_dislike, '--rp', label = 'dd_dislike')\n",
    "        ax_left.plot(iters_idx, dd_like, '--gp', label = 'dd_like')\n",
    "        lines_left, labels_left = ax_left.get_legend_handles_labels()   \n",
    "        ax_left.legend(lines_left, labels_left, loc=0)\n",
    "        ax_left.grid()\n",
    "        ax_left.set_xlabel(\"Training Iterations Done(n)\")\n",
    "        ax_left.set_ylabel(\"Softmax Probability\")\n",
    "        ax_left.set_title(\"Dislike to Dislike [correct]\")\n",
    "        plt.savefig(recordDir+'dd_record.png', bbox_inches='tight')\n",
    "        #dl\n",
    "        fig = plt.figure()\n",
    "        ax_left = fig.add_subplot(111)\n",
    "        ax_left.plot(iters_idx, dl_dislike, '--rp', label = 'dl_dislike')\n",
    "        ax_left.plot(iters_idx, dl_like, '--gp', label = 'dl_like')\n",
    "        lines_left, labels_left = ax_left.get_legend_handles_labels()   \n",
    "        ax_left.legend(lines_left, labels_left, loc=0)\n",
    "        ax_left.grid()\n",
    "        ax_left.set_xlabel(\"Training Iterations Done(n)\")\n",
    "        ax_left.set_ylabel(\"Softmax Probability\")\n",
    "        ax_left.set_title(\"Dislike to Like [wrong]\")\n",
    "        plt.savefig(recordDir+'dl_record.png', bbox_inches='tight')        \n",
    "        #d\n",
    "        fig = plt.figure()\n",
    "        ax_left = fig.add_subplot(111)\n",
    "        ax_left.plot(iters_idx, d_dislike, '--rp', label = 'd_dislike')\n",
    "        ax_left.plot(iters_idx, d_like, '--gp', label = 'd_like')\n",
    "        lines_left, labels_left = ax_left.get_legend_handles_labels()   \n",
    "        ax_left.legend(lines_left, labels_left, loc=0)\n",
    "        ax_left.grid()\n",
    "        ax_left.set_xlabel(\"Training Iterations Done(n)\")\n",
    "        ax_left.set_ylabel(\"Softmax Probability\")\n",
    "        ax_left.set_title(\"Dislike to Both\")\n",
    "        plt.savefig(recordDir+'d_record.png', bbox_inches='tight')  \n",
    "        #ld\n",
    "        fig = plt.figure()\n",
    "        ax_left = fig.add_subplot(111)\n",
    "        ax_left.plot(iters_idx, ld_dislike, '--rp', label = 'ld_dislike')\n",
    "        ax_left.plot(iters_idx, ld_like, '--gp', label = 'ld_like')\n",
    "        lines_left, labels_left = ax_left.get_legend_handles_labels()   \n",
    "        ax_left.legend(lines_left, labels_left, loc=0)\n",
    "        ax_left.grid()\n",
    "        ax_left.set_xlabel(\"Training Iterations Done(n)\")\n",
    "        ax_left.set_ylabel(\"Softmax Probability\")\n",
    "        ax_left.set_title(\"Like to Dislike [wrong]\")\n",
    "        plt.savefig(recordDir+'ld_record.png', bbox_inches='tight')  \n",
    "        #ll\n",
    "        fig = plt.figure()\n",
    "        ax_left = fig.add_subplot(111)\n",
    "        ax_left.plot(iters_idx, ll_dislike, '--rp', label = 'll_dislike')\n",
    "        ax_left.plot(iters_idx, ll_like, '--gp', label = 'll_like')\n",
    "        lines_left, labels_left = ax_left.get_legend_handles_labels()   \n",
    "        ax_left.legend(lines_left, labels_left, loc=0)\n",
    "        ax_left.grid()\n",
    "        ax_left.set_xlabel(\"Training Iterations Done(n)\")\n",
    "        ax_left.set_ylabel(\"Softmax Probability\")\n",
    "        ax_left.set_title(\"Like to Like [correct]\")\n",
    "        plt.savefig(recordDir+'ll_record.png', bbox_inches='tight')  \n",
    "        #l\n",
    "        fig = plt.figure()\n",
    "        ax_left = fig.add_subplot(111)\n",
    "        ax_left.plot(iters_idx, l_dislike, '--rp', label = 'l_dislike')\n",
    "        ax_left.plot(iters_idx, l_like, '--gp', label = 'l_like')\n",
    "        lines_left, labels_left = ax_left.get_legend_handles_labels()   \n",
    "        ax_left.legend(lines_left, labels_left, loc=0)\n",
    "        ax_left.grid()\n",
    "        ax_left.set_xlabel(\"Training Iterations Done(n)\")\n",
    "        ax_left.set_ylabel(\"Softmax Probability\")\n",
    "        ax_left.set_title(\"Like to Both\")\n",
    "        plt.savefig(recordDir+'l_record.png', bbox_inches='tight') \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg') # Must be before importing matplotlib.pyplot or pylab!\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "recordDir = '/local2/home/tong/fashionRecommendation/models/fashionNet_2/training_record/'\n",
    "\n",
    "conf_l_matrix_whole = []\n",
    "conf_r_matrix_whole = []\n",
    "conf_l_matrix_whole = open(recordDir+'conf_l_matrix.txt').readlines()\n",
    "conf_r_matrix_whole = open(recordDir+'conf_r_matrix.txt').readlines()\n",
    "\n",
    "# conf_l_matrix_whole = []\n",
    "# conf_r_matrix_whole = []\n",
    "# conf_l_matrix_whole = open('conf_l_matrix.txt').readlines()\n",
    "# conf_r_matrix_whole = open('conf_r_matrix.txt').readlines()\n",
    "conf_matrix = []\n",
    "for i in range(0,len(conf_l_matrix_whole)):\n",
    "    conf_matrix.append([int(conf_r_matrix_whole[i].split(' ')[1]),int(conf_r_matrix_whole[i].split(' ')[2]), \\\n",
    "                        int(conf_l_matrix_whole[i].split(' ')[3]),int(conf_l_matrix_whole[i].split(' ')[4])])\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "im = ax.imshow(np.array(conf_matrix).T, interpolation='nearest', cmap=plt.cm.jet)\n",
    "fig.colorbar(im, ax=ax)\n",
    "plt.xlabel('Caffemodel Index(n)')\n",
    "plt.ylabel('like(like,dislike), dislike(like,dislike)')\n",
    "plt.title('Confusion Matrix@(dislike,like)')\n",
    "ax.set_aspect(25)\n",
    "fig.set_size_inches(20.5, 12.5)\n",
    "fig.savefig(recordDir+'cMat.png',bbox_inches='tight')\n",
    "# fig.savefig('cMat.png',bbox_inches='tight')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
