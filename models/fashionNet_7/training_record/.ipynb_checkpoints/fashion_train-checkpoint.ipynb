{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') # Must be before importing matplotlib.pyplot or pylab!\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0,'/local2/home/tong/caffe-master/python')\n",
    "import caffe\n",
    "\n",
    "import os\n",
    "from matplotlib import rc\n",
    "rc('mathtext', default='regular')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caffe.set_mode_gpu()\n",
    "caffe.set_device(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for training\n",
    "solver = caffe.SGDSolver('/local2/home/tong/fashionRecommendation/models/fashionNet_7/fashion_solver_7.prototxt')\n",
    "solver.net.copy_from('/local2/home/tong/fashionRecommendation/models/VGG_M_2048/VGG_CNN_M_2048.caffemodel')\n",
    "solver.test_nets[0].copy_from('/local2/home/tong/fashionRecommendation/models/VGG_M_2048/VGG_CNN_M_2048.caffemodel')\n",
    "#solver.net.copy_from('/local2/home/tong/fashionRecommendation/models/fashionNet_7/training_record/fashion_params_7_***.caffemodel')\n",
    "#solver.test_nets[0].copy_from('/local2/home/tong/fashionRecommendation/models/fashionNet_7/training_record/fashion_params_7_***.caffemodel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for saving caffemodel\n",
    "net = caffe.Net('/local2/home/tong/fashionRecommendation/models/fashionNet_7/fashion_deploy_7.prototxt', caffe.TEST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#verify solver.net & solver.test_nets[0]\n",
    "solver.net.forward()\n",
    "solver.test_nets[0].forward()\n",
    "\n",
    "print(solver.net.blobs['accuracy'].data, \n",
    "      solver.test_nets[0].blobs['accuracy'].data)\n",
    "\n",
    "if solver.test_nets[0].blobs['accuracy'].data > 0.3:\n",
    "    print 'feasible!'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training solver.net\n",
    "recordDir = '/local2/home/tong/fashionRecommendation/models/fashionNet_7/training_record/'\n",
    "\n",
    "one_twen_epoch = 100000\n",
    "\n",
    "test_interval = one_twen_epoch * 2\n",
    "\n",
    "k = 0\n",
    "start_iter = 0\n",
    "end_iter = start_iter + one_twen_epoch*20\n",
    "\n",
    "params = net.params.keys()\n",
    "\n",
    "###################################\n",
    "#                                 #\n",
    "#                                 #\n",
    "###################################\n",
    "\n",
    "# record train (accuracy, loss)\n",
    "tr_accu = open(recordDir + 'train_accu.txt','a')\n",
    "tr_loss = open(recordDir + 'train_loss.txt','a')\n",
    "tr_accu.write('0 '+str(solver.net.blobs['accuracy'].data)+'\\r\\n')\n",
    "tr_loss.write('0 '+str(solver.net.blobs['rank_Loss'].data)+'\\r\\n')\n",
    "tr_accu.close()\n",
    "tr_loss.close()\n",
    "\n",
    "for i in range (start_iter,end_iter):\n",
    "    # update parameters\n",
    "    solver.step(1)\n",
    "    #save caffemodel every 1/20 epoch (~ one_twen_epoch iters)\n",
    "    if (i % (one_twen_epoch - 1) == 0):\n",
    "        #copy parameters solver.net -> net\n",
    "        source_params = {pr: (solver.net.params[pr][0].data,solver.net.params[pr][1].data) for pr in params}\n",
    "        target_params = {pr: (net.params[pr][0].data,net.params[pr][1].data) for pr in params}\n",
    "        for pr in params:\n",
    "            target_params[pr][0][...] = source_params[pr][0] #weights\n",
    "            target_params[pr][1][...] = source_params[pr][1] #bias\n",
    "        #save caffemodel\n",
    "        net.save(recordDir+'fashion_params_7_'+str(i+1)+'.caffemodel')\n",
    "    # record train (accuracy, loss)\n",
    "    tr_accu = open(recordDir + 'train_accu.txt','a')\n",
    "    tr_loss = open(recordDir + 'train_loss.txt','a')\n",
    "    tr_accu.write(str(i+1)+' '+str(solver.net.blobs['accuracy'].data)+'\\r\\n')\n",
    "    tr_loss.write(str(i+1)+' '+str(solver.net.blobs['rank_Loss'].data)+'\\r\\n')\n",
    "    tr_accu.close()\n",
    "    tr_loss.close()\n",
    "    # record test (accuracy, loss) every 1/10 epoch (~ test_interval iters)\n",
    "    if (i % (test_interval) == 0):\n",
    "        te_accu = open(recordDir + 'test_accu.txt','a')\n",
    "        te_loss = open(recordDir + 'test_loss.txt','a')\n",
    "        te_accu.write(str(i)+' '+str(solver.test_nets[0].blobs['accuracy'].data)+'\\r\\n')\n",
    "        te_loss.write(str(i)+' '+str(solver.test_nets[0].blobs['rank_Loss'].data)+'\\r\\n')\n",
    "        te_accu.close()\n",
    "        te_loss.close()\n",
    "        \n",
    "        #visualization for discovering overfitting\n",
    "        train_accu_whole = []\n",
    "        train_loss_whole = []\n",
    "        test_accu_whole = []\n",
    "        test_loss_whole = []\n",
    "\n",
    "        train_accu_whole = open(recordDir+'train_accu.txt').readlines() \n",
    "        train_loss_whole = open(recordDir+'train_loss.txt').readlines()\n",
    "        test_accu_whole = open(recordDir+'test_accu.txt').readlines()\n",
    "        test_loss_whole = open(recordDir+'test_loss.txt').readlines()\n",
    "\n",
    "        train_iter_idx = []\n",
    "        train_loss = []\n",
    "        train_accuracy = []\n",
    "\n",
    "        test_iter_idx = []\n",
    "        test_loss = []\n",
    "        test_accuracy = []\n",
    "\n",
    "        for i in range(0, len(train_accu_whole)):\n",
    "            #train_iter_idx\n",
    "            train_iter_idx.append(int(train_accu_whole[i].strip('\\r\\n').split(' ')[0]))\n",
    "            #train_loss\n",
    "            train_loss.append(float(train_loss_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "            #train_accuracy\n",
    "            train_accuracy.append(float(train_accu_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "\n",
    "        for i in range(0, len(test_accu_whole)):\n",
    "            #test_iter_idx\n",
    "            test_iter_idx.append(int(test_accu_whole[i].strip('\\r\\n').split(' ')[0]))\n",
    "            #test_loss\n",
    "            test_loss.append(float(test_loss_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "            #test_accuracy\n",
    "            test_accuracy.append(float(test_accu_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax_left = fig.add_subplot(111)\n",
    "        ax_left.plot(train_iter_idx, train_loss, '--rp', label = 'Training Loss')\n",
    "        ax_left.plot(test_iter_idx, test_loss, '--gp', label = 'Validation Loss')\n",
    "        ax_right = ax_left.twinx()\n",
    "        ax_right.plot(train_iter_idx, train_accuracy, '-bp', label = 'Training Accuracy')\n",
    "        ax_right.plot(test_iter_idx, test_accuracy, '-yp', label = 'Validation Accuracy')\n",
    "\n",
    "        # ask matplotlib for the plotted objects and their labels\n",
    "        lines_left, labels_left = ax_left.get_legend_handles_labels()\n",
    "        lines_right, labels_right = ax_right.get_legend_handles_labels()\n",
    "        ax_right.legend(lines_left + lines_right, labels_left + labels_right, loc=0)\n",
    "        ax_left.grid()\n",
    "        ax_left.set_xlabel(\"Training Iterations (n)\")\n",
    "        ax_left.set_ylabel(\"Loss\")\n",
    "        ax_right.set_ylabel(\"Accuracy\")\n",
    "        ax_right.set_title(\"Hightest Validation Accuracy: {:.3f}, at Training Iteration: {}\".format(max(test_accuracy), test_iter_idx[test_accuracy.index(max(test_accuracy))]))\n",
    "        plt.savefig(recordDir+'record.png', bbox_inches='tight')        \n",
    "        # ending criteria\n",
    "        if solver.test_nets[0].blobs['accuracy'].data > 0.93:\n",
    "            k = k + 1\n",
    "            if (k > 10):\n",
    "                print '\\n\\nValidation accuracy: {} > 0.93 counted for 10 times\\n\\n'.format(solver.test_nets[0].blobs['accuracy'].data)\n",
    "                break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#visualization for discovering overfitting\n",
    "import os\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') # Must be before importing matplotlib.pyplot or pylab!\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('mathtext', default='regular')\n",
    "\n",
    "#os.system('scp '+recordDir + 'train_accu.txt '+'/home/tonghe2/fashionRecommendation/models/fashionNet_7/training_record')\n",
    "#os.system('scp '+recordDir + 'train_loss.txt '+'/home/tonghe2/fashionRecommendation/models/fashionNet_7/training_record')\n",
    "#os.system('scp '+recordDir + 'test_accu.txt '+'/home/tonghe2/fashionRecommendation/models/fashionNet_7/training_record')\n",
    "#os.system('scp '+recordDir + 'test_loss.txt '+'/home/tonghe2/fashionRecommendation/models/fashionNet_7/training_record')\n",
    "\n",
    "train_accu_whole = []\n",
    "train_loss_whole = []\n",
    "test_accu_whole = []\n",
    "test_loss_whole = []\n",
    "\n",
    "train_accu_whole = open(recordDir+'train_accu.txt').readlines() \n",
    "train_loss_whole = open(recordDir+'train_loss.txt').readlines()\n",
    "test_accu_whole = open(recordDir+'test_accu.txt').readlines()\n",
    "test_loss_whole = open(recordDir+'test_loss.txt').readlines()\n",
    "\n",
    "train_iter_idx = []\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "\n",
    "test_iter_idx = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "\n",
    "for i in range(0, len(train_accu_whole)):\n",
    "    #train_iter_idx\n",
    "    train_iter_idx.append(int(train_accu_whole[i].strip('\\r\\n').split(' ')[0]))\n",
    "    #train_loss\n",
    "    train_loss.append(float(train_loss_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "    #train_accuracy\n",
    "    train_accuracy.append(float(train_accu_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "    \n",
    "for i in range(0, len(test_accu_whole)):\n",
    "    #test_iter_idx\n",
    "    test_iter_idx.append(int(test_accu_whole[i].strip('\\r\\n').split(' ')[0]))\n",
    "    #test_loss\n",
    "    test_loss.append(float(test_loss_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "    #test_accuracy\n",
    "    test_accuracy.append(float(test_accu_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "\n",
    "# for i in range(0, 20):\n",
    "#     train_iter_idx.append(i)\n",
    "#     train_loss.append(-2*i+1)\n",
    "#     train_accuracy.append(1.5*i*i)\n",
    "\n",
    "# for i in range(0, 10):\n",
    "#     test_iter_idx.append(2*i)\n",
    "#     test_loss.append(-1.5*i+3)\n",
    "#     test_accuracy.append(0.7*i*i)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax_left = fig.add_subplot(111)\n",
    "ax_left.plot(train_iter_idx, train_loss, '--rp', label = 'Training Loss')\n",
    "ax_left.plot(test_iter_idx, test_loss, '--gp', label = 'Validation Loss')\n",
    "ax_right = ax_left.twinx()\n",
    "ax_right.plot(train_iter_idx, train_accuracy, '-bp', label = 'Training Accuracy')\n",
    "ax_right.plot(test_iter_idx, test_accuracy, '-yp', label = 'Validation Accuracy')\n",
    "\n",
    "# ask matplotlib for the plotted objects and their labels\n",
    "lines_left, labels_left = ax_left.get_legend_handles_labels()\n",
    "lines_right, labels_right = ax_right.get_legend_handles_labels()\n",
    "ax_right.legend(lines_left + lines_right, labels_left + labels_right, loc=0)\n",
    "ax_left.grid()\n",
    "ax_left.set_xlabel(\"Training Iterations (n)\")\n",
    "ax_left.set_ylabel(\"Loss\")\n",
    "ax_right.set_ylabel(\"Accuracy\")\n",
    "ax_right.set_title(\"Hightest Validation Accuracy: {:.3f}, at Training Iteration: {}\".format(max(test_accuracy), test_iter_idx[test_accuracy.index(max(test_accuracy))]))\n",
    "plt.savefig(recordDir+'record.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scp tong@ares.cs.ucla.edu:/local2/home/tong/fashionRecommendation/models/fashionNet_7/training_record/record.png /home/tonghe2/fashionRecommendation/models/fashionNet_7/training_record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#copy parameters solver.net -> net\n",
    "params = net.params.keys()\n",
    "source_params = {pr: (solver.net.params[pr][0].data,solver.net.params[pr][1].data) for pr in params}\n",
    "target_params = {pr: (net.params[pr][0].data,net.params[pr][1].data) for pr in params}\n",
    "for pr in params:\n",
    "    target_params[pr][0][...] = source_params[pr][0] #weights\n",
    "    target_params[pr][1][...] = source_params[pr][1] #bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#verify params copy\n",
    "print 'solver.net: ', solver.net.params['metric_fc1'][0].data\n",
    "print 'net:', solver.net.params['metric_fc1'][0].data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save caffemodel\n",
    "net.save(recordDir+'fashion_params_7_'+str(i+1)+'.caffemodel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#verify caffemodel\n",
    "net_Verify = caffe.Net('/local2/home/tong/fashionRecommendation/models/fashionNet_7/fashion_deploy_7.prototxt',\n",
    "                recordDir+'fashion_params_7_'+str(i+1)+'.caffemodel',\n",
    "                caffe.TEST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#verify input data (posi outfit)\n",
    "\n",
    "#input VGG_mean.jpg\n",
    "blob = caffe.proto.caffe_pb2.BlobProto()\n",
    "data = open('./data/VGG_mean.binaryproto', 'rb' ).read()\n",
    "blob.ParseFromString(data)\n",
    "VGG_mean = np.array( caffe.io.blobproto_to_array(blob) )\n",
    "VGG_mean.astype(np.uint8)\n",
    "\n",
    "#get data from blobs\n",
    "top = np.array(solver.net.blobs['top'].data[0])\n",
    "bottom = np.array(solver.net.blobs['bottom'].data[0])\n",
    "shoes = np.array(solver.net.blobs['shoes'].data[0])\n",
    "#change data type to np.uint8\n",
    "top.astype(np.uint8)\n",
    "bottom.astype(np.uint8)\n",
    "shoes.astype(np.uint8)\n",
    "#add VGG_mean\n",
    "top = top + VGG_mean[0,]\n",
    "bottom = bottom + VGG_mean[0,]\n",
    "shoes = shoes + VGG_mean[0,]\n",
    "#BGR to RGB\n",
    "top = np.array([top[2,],top[1,],top[0,]])\n",
    "bottom = np.array([bottom[2,],bottom[1,],bottom[0,]])\n",
    "shoes = np.array([shoes[2,],shoes[1,],shoes[0,]])\n",
    "#(C,H,W) to (H,W,C)\n",
    "top = np.rollaxis(top,0,3)\n",
    "bottom = np.rollaxis(bottom,0,3)\n",
    "shoes = np.rollaxis(shoes,0,3)\n",
    "#temp buffer for using Image.fromarray(*)\n",
    "temp_top = np.zeros(top.shape,np.uint8)\n",
    "temp_bottom = np.zeros(bottom.shape,np.uint8)\n",
    "temp_shoes = np.zeros(shoes.shape,np.uint8)\n",
    "#copy data to buffer\n",
    "for i in range(0,top.shape[0]):\n",
    "    for j in range(0,top.shape[1]):\n",
    "        for k in range(0,top.shape[2]):\n",
    "            temp_top[i,j,k] = top[i,j,k]\n",
    "            temp_bottom[i,j,k] = bottom[i,j,k]\n",
    "            temp_shoes[i,j,k] = shoes[i,j,k]\n",
    "#np.array 2 image\n",
    "import Image\n",
    "img_top = Image.fromarray(temp_top)\n",
    "img_bottom = Image.fromarray(temp_bottom)\n",
    "img_shoes = Image.fromarray(temp_shoes)\n",
    "#save images\n",
    "img_top.save('./top.jpg')\n",
    "img_bottom.save('./bottom.jpg')\n",
    "img_shoes.save('./shoes.jpg')\n",
    "\n",
    "#verify input data (nega outfit)\n",
    "#get data from blobs\n",
    "top = np.array(solver.test_nets[0].blobs['top_n'].data[49])\n",
    "bottom = np.array(solver.test_nets[0].blobs['bottom_n'].data[49])\n",
    "shoes = np.array(solver.test_nets[0].blobs['shoes_n'].data[49])\n",
    "#change data type to np.uint8\n",
    "top.astype(np.uint8)\n",
    "bottom.astype(np.uint8)\n",
    "shoes.astype(np.uint8)\n",
    "#add VGG_mean\n",
    "top = top + VGG_mean\n",
    "bottom = bottom + VGG_mean\n",
    "shoes = shoes + VGG_mean\n",
    "#BGR to RGB\n",
    "top = np.array([top[2,],top[1,],top[0,]])\n",
    "bottom = np.array([bottom[2,],bottom[1,],bottom[0,]])\n",
    "shoes = np.array([shoes[2,],shoes[1,],shoes[0,]])\n",
    "#(C,H,W) to (H,W,C)\n",
    "top = np.rollaxis(top,0,3)\n",
    "bottom = np.rollaxis(bottom,0,3)\n",
    "shoes = np.rollaxis(shoes,0,3)\n",
    "#temp buffer for using Image.fromarray(*)\n",
    "temp_top = np.zeros(top.shape,np.uint8)\n",
    "temp_bottom = np.zeros(bottom.shape,np.uint8)\n",
    "temp_shoes = np.zeros(shoes.shape,np.uint8)\n",
    "#copy data to buffer\n",
    "for i in range(0,top.shape[0]):\n",
    "    for j in range(0,top.shape[1]):\n",
    "        for k in range(0,top.shape[2]):\n",
    "            temp_top[i,j,k] = top[i,j,k]\n",
    "            temp_bottom[i,j,k] = bottom[i,j,k]\n",
    "            temp_shoes[i,j,k] = shoes[i,j,k]\n",
    "#np.array 2 image\n",
    "import Image\n",
    "img_top = Image.fromarray(temp_top)\n",
    "img_bottom = Image.fromarray(temp_bottom)\n",
    "img_shoes = Image.fromarray(temp_shoes)\n",
    "#save images\n",
    "img_top.save('./top_n.jpg')\n",
    "img_bottom.save('./bottom_n.jpg')\n",
    "img_shoes.save('./shoes_n.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
