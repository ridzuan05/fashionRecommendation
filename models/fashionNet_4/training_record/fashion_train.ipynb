{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') # Must be before importing matplotlib.pyplot or pylab!\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0,'/local2/home/tong/caffe-master/python')\n",
    "import caffe\n",
    "\n",
    "import os\n",
    "from matplotlib import rc\n",
    "rc('mathtext', default='regular')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caffe.set_mode_gpu()\n",
    "caffe.set_device(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for training\n",
    "solver = caffe.SGDSolver('/local2/home/tong/fashionRecommendation/models/fashionNet_4/fashion_solver_4.prototxt')\n",
    "#CHANGE!!!\n",
    "solver.net.copy_from('/local2/home/tong/fashionRecommendation/models/VGG_M_2048/VGG_CNN_M_2048.caffemodel')\n",
    "#CHANGE!!!\n",
    "solver.test_nets[0].copy_from('/local2/home/tong/fashionRecommendation/models/VGG_M_2048/VGG_CNN_M_2048.caffemodel')\n",
    "#solver.net.copy_from('/local2/home/tong/fashionRecommendation/models/fashionNet_4/training_record/fashion_params_4_***.caffemodel')\n",
    "#solver.test_nets[0].copy_from('/local2/home/tong/fashionRecommendation/models/fashionNet_4/training_record/fashion_params_4_***.caffemodel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for saving caffemodel\n",
    "net = caffe.Net('/local2/home/tong/fashionRecommendation/models/fashionNet_4/fashion_deploy_4.prototxt', caffe.TEST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #verify solver.net & solver.test_nets[0]\n",
    "# solver.net.forward()\n",
    "# solver.test_nets[0].forward()\n",
    "\n",
    "# print(solver.net.blobs['loss'].data, \n",
    "#       solver.test_nets[0].blobs['loss'].data)\n",
    "\n",
    "# if solver.test_nets[0].blobs['loss'].data < 1000:\n",
    "#     print 'feasible!'\n",
    "# else:\n",
    "#     print 'alright!'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_avg(test_iter):\n",
    "#     avg_accu = 0\n",
    "    avg_loss = 0\n",
    "    for i in range(0,test_iter):\n",
    "        solver.test_nets[0].forward()\n",
    "#         avg_accu = avg_accu + solver.test_nets[0].blobs['accuracy'].data\n",
    "        avg_loss = avg_loss + solver.test_nets[0].blobs['loss'].data\n",
    "    return (avg_loss/test_iter)#, (avg_accu/test_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training solver.net\n",
    "recordDir = '/local2/home/tong/fashionRecommendation/models/fashionNet_4/training_record/'\n",
    "\n",
    "one_twen_epoch = 184 # 1/150 train epoch\n",
    "test_interval = 184 # 1/150 train epoch\n",
    "\n",
    "test_iter = 180 # 1 test epoch\n",
    "\n",
    "k = 0\n",
    "start_iter = 0 #CHANGE!!!\n",
    "end_iter = 9178*3 #3 epoch CHANGE!!!\n",
    "\n",
    "params = net.params.keys()\n",
    "\n",
    "solver.net.forward() #CHANGE!!!\n",
    "\n",
    "# train_accu = 0 #CHANGE!!!\n",
    "train_los = 0 #CHANGE!!!\n",
    "# train_avg_accu = 0\n",
    "train_avg_loss = 0\n",
    "# train_cur_accu = 0\n",
    "train_cur_loss = 0\n",
    "# test_accu = 0\n",
    "test_loss = 0\n",
    "\n",
    "for i in range (start_iter,end_iter+1):\n",
    "# if (i != start_iter): #CHANGE!!!\n",
    "    # save train data\n",
    "#     tr_avg_accu = open(recordDir + 'train_avg_accu.txt','a')\n",
    "    tr_avg_loss = open(recordDir + 'train_avg_loss.txt','a')\n",
    "#     train_accu = train_accu + solver.net.blobs['accuracy'].data\n",
    "    train_los = train_los + solver.net.blobs['loss'].data\n",
    "#     train_avg_accu = train_accu/(i+1)\n",
    "    train_avg_loss = train_los/(i+1)\n",
    "#     tr_avg_accu.write(str(i)+' '+str(train_avg_accu)+'\\r\\n')\n",
    "    tr_avg_loss.write(str(i)+' '+str(train_avg_loss)+'\\r\\n')\n",
    "#     tr_avg_accu.close()\n",
    "    tr_avg_loss.close()\n",
    "    if(i%5==0):\n",
    "        print(\"\\nIters done:{}, avg_loss={}.\\n\".format(i,train_avg_loss))\n",
    "#     tr_accu = open(recordDir + 'train_accu.txt','a')\n",
    "    tr_loss = open(recordDir + 'train_loss.txt','a')\n",
    "#     train_cur_accu = solver.net.blobs['accuracy'].data\n",
    "    train_cur_loss = solver.net.blobs['loss'].data\n",
    "#     tr_accu.write(str(i)+' '+str(train_cur_accu)+'\\r\\n')\n",
    "    tr_loss.write(str(i)+' '+str(train_cur_loss)+'\\r\\n')\n",
    "#     tr_accu.close()\n",
    "    tr_loss.close()\n",
    "    if(i%5==0):\n",
    "        print(\"              bat_loss={}.\\n\".format(train_cur_loss))\n",
    "    # validation, save caffemodel, visualization, and stop criteria\n",
    "    if (i%test_interval==0 or i==end_iter):\n",
    "        # validation\n",
    "        test_loss=test_avg(test_iter)\n",
    "#         te_accu = open(recordDir + 'test_accu.txt','a')\n",
    "        te_loss = open(recordDir + 'test_loss.txt','a')\n",
    "#         te_accu.write(str(i)+' '+str(test_accu)+'\\r\\n')\n",
    "        te_loss.write(str(i)+' '+str(test_loss)+'\\r\\n')\n",
    "#         te_accu.close()\n",
    "        te_loss.close()\n",
    "        print(\"\\nIters done:{}, VAL_loss={}.\\n\".format(i,test_loss))\n",
    "        # save caffemodel\n",
    "        source_params = {pr: (solver.net.params[pr][0].data,solver.net.params[pr][1].data) for pr in params}\n",
    "        target_params = {pr: (net.params[pr][0].data,net.params[pr][1].data) for pr in params}\n",
    "        for pr in params:\n",
    "            target_params[pr][0][...] = source_params[pr][0] #weights\n",
    "            target_params[pr][1][...] = source_params[pr][1] #bias\n",
    "        net.save(recordDir+'fashion_params_4_'+str(i)+'.caffemodel') \n",
    "        #visualization for discovering overfitting\n",
    "#         train_accu_whole = []\n",
    "        train_loss_whole = []\n",
    "#         test_accu_whole = []\n",
    "        test_loss_whole = []\n",
    "#         train_accu_whole = open(recordDir+'train_avg_accu.txt').readlines() \n",
    "        train_loss_whole = open(recordDir+'train_avg_loss.txt').readlines()\n",
    "#         test_accu_whole = open(recordDir+'test_accu.txt').readlines()\n",
    "        test_loss_whole = open(recordDir+'test_loss.txt').readlines()\n",
    "        train_iter_idx = []\n",
    "        train_loss = []\n",
    "#         train_accuracy = []\n",
    "        test_iter_idx = []\n",
    "        test_loss = []\n",
    "#         test_accuracy = []\n",
    "        for i in range(0, len(train_loss_whole)):\n",
    "#             if i % test_interval == 0:\n",
    "            #train_iter_idx\n",
    "            train_iter_idx.append(int(train_loss_whole[i].strip('\\r\\n').split(' ')[0]))\n",
    "            #train_loss\n",
    "            train_loss.append(float(train_loss_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "            #train_accuracy\n",
    "#             train_accuracy.append(float(train_accu_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "        for i in range(0, len(test_loss_whole)):\n",
    "            #test_iter_idx\n",
    "            test_iter_idx.append(int(test_loss_whole[i].strip('\\r\\n').split(' ')[0]))\n",
    "            #test_loss\n",
    "            test_loss.append(float(test_loss_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "            #test_accuracy\n",
    "#             test_accuracy.append(float(test_accu_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "        fig = plt.figure()\n",
    "        ax_left = fig.add_subplot(111)\n",
    "        ax_left.plot(train_iter_idx, train_loss, '--rp', label = 'Avg_T_Loss')\n",
    "        ax_left.plot(test_iter_idx, test_loss, '--gp', label = 'Avg_V_Loss')\n",
    "#         ax_right = ax_left.twinx()\n",
    "#         ax_right.plot(train_iter_idx, train_accuracy, '-bp', label = 'Avg_T_Accuracy')\n",
    "#         ax_right.plot(test_iter_idx, test_accuracy, '-yp', label = 'Avg_V_Accuracy')\n",
    "        # ask matplotlib for the plotted objects and their labels\n",
    "        lines_left, labels_left = ax_left.get_legend_handles_labels()\n",
    "#         lines_right, labels_right = ax_right.get_legend_handles_labels()\n",
    "        ax_left.legend(lines_left, labels_left, loc=0)\n",
    "#         ax_right.legend(lines_left + lines_right, labels_left + labels_right, loc=0)\n",
    "        ax_left.grid()\n",
    "        ax_left.set_xlabel(\"Training Iterations Done(n)\")\n",
    "        ax_left.set_ylabel(\"Loss\")\n",
    "#         ax_right.set_ylabel(\"Accuracy\")\n",
    "        ax_left.set_title(\"LVL@({:.3f},{})\".format(min(test_loss),test_iter_idx[test_loss.index(min(test_loss))]))\n",
    "        plt.savefig(recordDir+'record.png', bbox_inches='tight')\n",
    "#         train_accu_whole = []\n",
    "        train_loss_whole = []\n",
    "#         test_accu_whole = []\n",
    "        test_loss_whole = []\n",
    "#         train_accu_whole = open(recordDir+'train_accu.txt').readlines() \n",
    "        train_loss_whole = open(recordDir+'train_loss.txt').readlines()\n",
    "#         test_accu_whole = open(recordDir+'test_accu.txt').readlines()\n",
    "        test_loss_whole = open(recordDir+'test_loss.txt').readlines()\n",
    "        train_iter_idx = []\n",
    "        train_loss = []\n",
    "#         train_accuracy = []\n",
    "        test_iter_idx = []\n",
    "        test_loss = []\n",
    "#         test_accuracy = []\n",
    "        for i in range(0, len(train_loss_whole)):\n",
    "#             if i % test_interval == 0:\n",
    "            #train_iter_idx\n",
    "            train_iter_idx.append(int(train_loss_whole[i].strip('\\r\\n').split(' ')[0]))\n",
    "            #train_loss\n",
    "            train_loss.append(float(train_loss_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "            #train_accuracy\n",
    "#             train_accuracy.append(float(train_accu_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "        for i in range(0, len(test_loss_whole)):\n",
    "            #test_iter_idx\n",
    "            test_iter_idx.append(int(test_loss_whole[i].strip('\\r\\n').split(' ')[0]))\n",
    "            #test_loss\n",
    "            test_loss.append(float(test_loss_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "            #test_accuracy\n",
    "#             test_accuracy.append(float(test_accu_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "        fig = plt.figure()\n",
    "        ax_left = fig.add_subplot(111)\n",
    "        ax_left.plot(train_iter_idx, train_loss, '--rp', label = 'Cur_T_Loss')\n",
    "        ax_left.plot(test_iter_idx, test_loss, '--gp', label = 'Avg_V_Loss')\n",
    "#         ax_right = ax_left.twinx()\n",
    "#         ax_right.plot(train_iter_idx, train_accuracy, '-bp', label = 'Cur_T_Accuracy')\n",
    "#         ax_right.plot(test_iter_idx, test_accuracy, '-yp', label = 'Avg_V_Accuracy')\n",
    "        # ask matplotlib for the plotted objects and their labels\n",
    "        lines_left, labels_left = ax_left.get_legend_handles_labels()\n",
    "#         lines_right, labels_right = ax_right.get_legend_handles_labels()\n",
    "        ax_left.legend(lines_left, labels_left, loc=0)\n",
    "#         ax_right.legend(lines_left + lines_right, labels_left + labels_right, loc=0)\n",
    "        ax_left.grid()\n",
    "        ax_left.set_xlabel(\"Training Iterations Done(n)\")\n",
    "        ax_left.set_ylabel(\"Loss\")\n",
    "#         ax_right.set_ylabel(\"Accuracy\")\n",
    "        ax_left.set_title(\"LVL@({:.3f},{})\".format(min(test_loss),test_iter_idx[test_loss.index(min(test_loss))]))\n",
    "        plt.savefig(recordDir+'cur_record.png', bbox_inches='tight')\n",
    "        # stop criteria\n",
    "        if test_loss < 0.07257:\n",
    "            k = k + 1\n",
    "            if (k > 10):\n",
    "                print '\\n\\nValidation loss: {} < 0.07257 counted for 10 times\\n\\n'.format(test_loss)\n",
    "                break\n",
    "    # update parameters\n",
    "    solver.step(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#visualization for discovering overfitting\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') # Must be before importing matplotlib.pyplot or pylab!\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0,'/home/tonghe2/caffe-master/python')\n",
    "import caffe\n",
    "\n",
    "import os\n",
    "from matplotlib import rc\n",
    "rc('mathtext', default='regular')\n",
    "\n",
    "recordDir = '/home/tonghe2/fashionRecommendation/models/fashionNet_4/training_record/'\n",
    "\n",
    "#os.system('scp '+recordDir + 'train_loss.txt '+'/home/tonghe2/fashionRecommendation/models/fashionNet_3/training_record')\n",
    "#os.system('scp '+recordDir + 'test_loss.txt '+'/home/tonghe2/fashionRecommendation/models/fashionNet_3/training_record')\n",
    "\n",
    "train_loss_whole = []\n",
    "test_loss_whole = []\n",
    " \n",
    "train_loss_whole = open(recordDir+'train_loss.txt').readlines()\n",
    "test_loss_whole = open(recordDir+'test_loss.txt').readlines()\n",
    "\n",
    "train_iter_idx = []\n",
    "train_loss = []\n",
    "\n",
    "test_iter_idx = []\n",
    "test_loss = []\n",
    "\n",
    "downSample = 408\n",
    "\n",
    "for i in range(0, len(train_accu_whole)):\n",
    "    if i % downSample == 0: \n",
    "        #train_iter_idx\n",
    "        train_iter_idx.append(int(train_accu_whole[i].strip('\\r\\n').split(' ')[0]))\n",
    "        #train_loss\n",
    "        train_loss.append(float(train_loss_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "    \n",
    "for i in range(0, len(test_accu_whole)):\n",
    "    #test_iter_idx\n",
    "    test_iter_idx.append(int(test_accu_whole[i].strip('\\r\\n').split(' ')[0]))\n",
    "    #test_loss\n",
    "    test_loss.append(float(test_loss_whole[i].strip('\\r\\n').split(' ')[1]))\n",
    "\n",
    "# for i in range(0, 20):\n",
    "#     train_iter_idx.append(i)\n",
    "#     train_loss.append(-2*i+1)\n",
    "#     train_accuracy.append(1.5*i*i)\n",
    "\n",
    "# for i in range(0, 10):\n",
    "#     test_iter_idx.append(2*i)\n",
    "#     test_loss.append(-1.5*i+3)\n",
    "#     test_accuracy.append(0.7*i*i)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax_left = fig.add_subplot(111)\n",
    "ax_left.plot(train_iter_idx, train_loss, '--rp', label = 'Training Loss')\n",
    "ax_left.plot(test_iter_idx, test_loss, '--gp', label = 'Validation Loss')\n",
    "\n",
    "# ask matplotlib for the plotted objects and their labels\n",
    "lines_left, labels_left = ax_left.get_legend_handles_labels()\n",
    "ax_left.legend(lines_left, labels_left, loc=0)\n",
    "ax_left.grid()\n",
    "ax_left.set_xlabel(\"Training Iterations (n)\")\n",
    "ax_left.set_ylabel(\"Loss\")\n",
    "ax_left.set_title(\"Lowest Validation Loss: {:.3f}, at Training Iteration: {}\".format(min(test_loss), test_iter_idx[test_loss.index(min(test_loss))]))\n",
    "plt.savefig(recordDir+'record_less.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scp tong@ares.cs.ucla.edu:/local2/home/tong/fashionRecommendation/models/fashionNet_4/training_record/record.png /home/tonghe2/fashionRecommendation/models/fashionNet_4/training_record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#copy parameters solver.net -> net\n",
    "params = net.params.keys()\n",
    "source_params = {pr: (solver.net.params[pr][0].data,solver.net.params[pr][1].data) for pr in params}\n",
    "target_params = {pr: (net.params[pr][0].data,net.params[pr][1].data) for pr in params}\n",
    "for pr in params:\n",
    "    target_params[pr][0][...] = source_params[pr][0] #weights\n",
    "    target_params[pr][1][...] = source_params[pr][1] #bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#verify params copy\n",
    "print 'solver.net: ', solver.net.params['metric_fc1'][0].data\n",
    "print 'net:', solver.net.params['metric_fc1'][0].data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save caffemodel\n",
    "net.save(recordDir+'fashion_params_4_'+str(i+1)+'.caffemodel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#verify caffemodel\n",
    "net_Verify = caffe.Net('/local2/home/tong/fashionRecommendation/models/fashionNet_4/fashion_deploy_4.prototxt',\n",
    "                recordDir+'fashion_params_4_'+str(i+1)+'.caffemodel',\n",
    "                caffe.TEST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#verify input data (posi outfit)\n",
    "\n",
    "#input VGG_mean.jpg\n",
    "blob = caffe.proto.caffe_pb2.BlobProto()\n",
    "data = open('./data/VGG_mean.binaryproto', 'rb' ).read()\n",
    "blob.ParseFromString(data)\n",
    "VGG_mean = np.array( caffe.io.blobproto_to_array(blob) )\n",
    "VGG_mean.astype(np.uint8)\n",
    "\n",
    "#get data from blobs\n",
    "top = np.array(solver.net.blobs['top'].data[0])\n",
    "bottom = np.array(solver.net.blobs['bottom'].data[0])\n",
    "shoes = np.array(solver.net.blobs['shoes'].data[0])\n",
    "#change data type to np.uint8\n",
    "top.astype(np.uint8)\n",
    "bottom.astype(np.uint8)\n",
    "shoes.astype(np.uint8)\n",
    "#add VGG_mean\n",
    "top = top + VGG_mean[0,]\n",
    "bottom = bottom + VGG_mean[0,]\n",
    "shoes = shoes + VGG_mean[0,]\n",
    "#BGR to RGB\n",
    "top = np.array([top[2,],top[1,],top[0,]])\n",
    "bottom = np.array([bottom[2,],bottom[1,],bottom[0,]])\n",
    "shoes = np.array([shoes[2,],shoes[1,],shoes[0,]])\n",
    "#(C,H,W) to (H,W,C)\n",
    "top = np.rollaxis(top,0,3)\n",
    "bottom = np.rollaxis(bottom,0,3)\n",
    "shoes = np.rollaxis(shoes,0,3)\n",
    "#temp buffer for using Image.fromarray(*)\n",
    "temp_top = np.zeros(top.shape,np.uint8)\n",
    "temp_bottom = np.zeros(bottom.shape,np.uint8)\n",
    "temp_shoes = np.zeros(shoes.shape,np.uint8)\n",
    "#copy data to buffer\n",
    "for i in range(0,top.shape[0]):\n",
    "    for j in range(0,top.shape[1]):\n",
    "        for k in range(0,top.shape[2]):\n",
    "            temp_top[i,j,k] = top[i,j,k]\n",
    "            temp_bottom[i,j,k] = bottom[i,j,k]\n",
    "            temp_shoes[i,j,k] = shoes[i,j,k]\n",
    "#np.array 2 image\n",
    "import Image\n",
    "img_top = Image.fromarray(temp_top)\n",
    "img_bottom = Image.fromarray(temp_bottom)\n",
    "img_shoes = Image.fromarray(temp_shoes)\n",
    "#save images\n",
    "img_top.save('./top.jpg')\n",
    "img_bottom.save('./bottom.jpg')\n",
    "img_shoes.save('./shoes.jpg')\n",
    "\n",
    "#verify input data (nega outfit)\n",
    "#get data from blobs\n",
    "top = np.array(solver.test_nets[0].blobs['top_n'].data[49])\n",
    "bottom = np.array(solver.test_nets[0].blobs['bottom_n'].data[49])\n",
    "shoes = np.array(solver.test_nets[0].blobs['shoes_n'].data[49])\n",
    "#change data type to np.uint8\n",
    "top.astype(np.uint8)\n",
    "bottom.astype(np.uint8)\n",
    "shoes.astype(np.uint8)\n",
    "#add VGG_mean\n",
    "top = top + VGG_mean\n",
    "bottom = bottom + VGG_mean\n",
    "shoes = shoes + VGG_mean\n",
    "#BGR to RGB\n",
    "top = np.array([top[2,],top[1,],top[0,]])\n",
    "bottom = np.array([bottom[2,],bottom[1,],bottom[0,]])\n",
    "shoes = np.array([shoes[2,],shoes[1,],shoes[0,]])\n",
    "#(C,H,W) to (H,W,C)\n",
    "top = np.rollaxis(top,0,3)\n",
    "bottom = np.rollaxis(bottom,0,3)\n",
    "shoes = np.rollaxis(shoes,0,3)\n",
    "#temp buffer for using Image.fromarray(*)\n",
    "temp_top = np.zeros(top.shape,np.uint8)\n",
    "temp_bottom = np.zeros(bottom.shape,np.uint8)\n",
    "temp_shoes = np.zeros(shoes.shape,np.uint8)\n",
    "#copy data to buffer\n",
    "for i in range(0,top.shape[0]):\n",
    "    for j in range(0,top.shape[1]):\n",
    "        for k in range(0,top.shape[2]):\n",
    "            temp_top[i,j,k] = top[i,j,k]\n",
    "            temp_bottom[i,j,k] = bottom[i,j,k]\n",
    "            temp_shoes[i,j,k] = shoes[i,j,k]\n",
    "#np.array 2 image\n",
    "import Image\n",
    "img_top = Image.fromarray(temp_top)\n",
    "img_bottom = Image.fromarray(temp_bottom)\n",
    "img_shoes = Image.fromarray(temp_shoes)\n",
    "#save images\n",
    "img_top.save('./top_n.jpg')\n",
    "img_bottom.save('./bottom_n.jpg')\n",
    "img_shoes.save('./shoes_n.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
